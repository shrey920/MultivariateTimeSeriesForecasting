{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultivariateTimeSeriesForecasting.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lCeSgYJHW-2r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0MZjMHaq9L67",
        "colab_type": "code",
        "outputId": "09e591dc-4d33-470b-ffb4-0e78b0df41cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!nvcc --version\n",
        "# !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "!pip install -q https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n",
            "\u001b[K    100% |████████████████████████████████| 753.6MB 20kB/s \n",
            "\u001b[31mfastai 1.0.51 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RY0Pd8eEXGe4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import math\n",
        "import time\n",
        "import numpy as np;\n",
        "import importlib\n",
        "\n",
        "import torch.optim\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-kwQxvbXPan",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LSTNet(nn.Module):\n",
        "    def __init__(self, args, data):\n",
        "        super(LSTNet, self).__init__()\n",
        "#         self.use_cuda = args.cuda\n",
        "        self.P = args.window;\n",
        "        self.m = data.m\n",
        "        self.hidR = args.hidRNN;\n",
        "        self.hidC = args.hidCNN;\n",
        "        self.hidS = args.hidSkip;\n",
        "        self.Ck = args.CNN_kernel;\n",
        "        self.skip = args.skip;\n",
        "        self.pt = (self.P - self.Ck)//self.skip\n",
        "        self.hw = args.highway_window\n",
        "        self.conv1 = nn.Conv2d(1, self.hidC, kernel_size = (self.Ck, self.m));\n",
        "        self.GRU1 = nn.GRU(self.hidC, self.hidR);\n",
        "        self.dropout = nn.Dropout(p = args.dropout);\n",
        "        if (self.skip > 0):\n",
        "            self.GRUskip = nn.GRU(self.hidC, self.hidS);\n",
        "            self.linear1 = nn.Linear(self.hidR + self.skip * self.hidS, self.m);\n",
        "        else:\n",
        "            self.linear1 = nn.Linear(self.hidR, self.m);\n",
        "        if (self.hw > 0):\n",
        "            self.highway = nn.Linear(self.hw, 1);\n",
        "        self.output = None;\n",
        "        if (args.output_fun == 'sigmoid'):\n",
        "            self.output = F.sigmoid;\n",
        "        if (args.output_fun == 'tanh'):\n",
        "            self.output = F.tanh;\n",
        " \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0);\n",
        "        \n",
        "        #CNN\n",
        "        c = x.view(-1, 1, self.P, self.m);\n",
        "        c = F.relu(self.conv1(c));\n",
        "        c = self.dropout(c);\n",
        "        c = torch.squeeze(c, 3);\n",
        "        \n",
        "        # RNN \n",
        "        r = c.permute(2, 0, 1).contiguous();\n",
        "        _, r = self.GRU1(r);\n",
        "        r = self.dropout(torch.squeeze(r,0));\n",
        "\n",
        "        \n",
        "        #skip-rnn\n",
        "        \n",
        "        if (self.skip > 0):\n",
        "            s = c[:,:, int(-self.pt * self.skip):].contiguous();\n",
        "            s = s.view(batch_size, self.hidC, self.pt, self.skip);\n",
        "            s = s.permute(2,0,3,1).contiguous();\n",
        "            s = s.view(self.pt, batch_size * self.skip, self.hidC);\n",
        "            _, s = self.GRUskip(s);\n",
        "            s = s.view(batch_size, self.skip * self.hidS);\n",
        "            s = self.dropout(s);\n",
        "            r = torch.cat((r,s),1);\n",
        "        \n",
        "        res = self.linear1(r);\n",
        "        \n",
        "        #autoregressive\n",
        "        if (self.hw > 0):\n",
        "            z = x[:, -self.hw:, :];\n",
        "            z = z.permute(0,2,1).contiguous().view(-1, self.hw);\n",
        "            z = self.highway(z);\n",
        "            z = z.view(-1,self.m);\n",
        "            res = res + z;\n",
        "            \n",
        "        if (self.output):\n",
        "            res = self.output(res);\n",
        "        return res;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NzDum9WcXfbR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normal_std(x):\n",
        "    return x.std() * np.sqrt((len(x) - 1.)/(len(x)))\n",
        "\n",
        "class Data_utility(object):\n",
        "    # train and valid is the ratio of training set and validation set. test = 1 - train - valid\n",
        "    def __init__(self, file_name, train, valid,  horizon, window, normalize = 2):\n",
        "#         self.cuda = cuda;\n",
        "        self.P = window\n",
        "        self.h = horizon\n",
        "        fin = open(file_name)\n",
        "        self.rawdat = np.loadtxt(fin,delimiter=',')\n",
        "        self.dat = np.zeros(self.rawdat.shape)\n",
        "        self.n, self.m = self.dat.shape\n",
        "        self.normalize = 2\n",
        "        self.scale = np.ones(self.m)\n",
        "        self._normalized(normalize)\n",
        "        self._split(int(train * self.n), int((train+valid) * self.n), self.n)\n",
        "        self.scale = torch.from_numpy(self.scale).float()\n",
        "        tmp = self.test[1] * self.scale.expand(self.test[1].size(0), self.m)\n",
        "            \n",
        "#         if self.cuda:\n",
        "#             self.scale = self.scale.cuda();\n",
        "#         self.scale = Variable(self.scale);\n",
        "        \n",
        "        self.rse = normal_std(tmp)\n",
        "        self.rae = torch.mean(torch.abs(tmp - torch.mean(tmp)))\n",
        "    \n",
        "    def _normalized(self, normalize):\n",
        "        #normalized by the maximum value of entire matrix.\n",
        "       \n",
        "        if (normalize == 0):\n",
        "            self.dat = self.rawdat\n",
        "            \n",
        "        if (normalize == 1):\n",
        "            self.dat = self.rawdat / np.max(self.rawdat)\n",
        "            \n",
        "        #normlized by the maximum value of each row(sensor).\n",
        "        if (normalize == 2):\n",
        "            for i in range(self.m):\n",
        "                self.scale[i] = np.max(np.abs(self.rawdat[:,i]))\n",
        "                self.dat[:,i] = self.rawdat[:,i] / np.max(np.abs(self.rawdat[:,i]))\n",
        "            \n",
        "        \n",
        "    def _split(self, train, valid, test):\n",
        "        \n",
        "        train_set = range(self.P+self.h-1, train)\n",
        "        valid_set = range(train, valid)\n",
        "        test_set = range(valid, self.n)\n",
        "        self.train = self._batchify(train_set, self.h)\n",
        "        self.valid = self._batchify(valid_set, self.h)\n",
        "        self.test = self._batchify(test_set, self.h)\n",
        "        \n",
        "        \n",
        "    def _batchify(self, idx_set, horizon):\n",
        "        \n",
        "        n = len(idx_set)\n",
        "        X = torch.zeros((n,self.P,self.m))\n",
        "        Y = torch.zeros((n,self.m))\n",
        "        \n",
        "        for i in range(n):\n",
        "            end = idx_set[i] - self.h + 1\n",
        "            start = end - self.P\n",
        "            X[i,:,:] = torch.from_numpy(self.dat[start:end, :])\n",
        "            Y[i,:] = torch.from_numpy(self.dat[idx_set[i], :])\n",
        "\n",
        "        return [X, Y]\n",
        "\n",
        "    def get_batches(self, inputs, targets, batch_size, shuffle=True):\n",
        "        length = len(inputs)\n",
        "        if shuffle:\n",
        "            index = torch.randperm(length)\n",
        "        else:\n",
        "            index = torch.LongTensor(range(length))\n",
        "        start_idx = 0\n",
        "        while (start_idx < length):\n",
        "            end_idx = min(length, start_idx + batch_size)\n",
        "            excerpt = index[start_idx:end_idx]\n",
        "            X = inputs[excerpt]; Y = targets[excerpt]\n",
        "#             if (self.cuda):\n",
        "#                 X = X.cuda()\n",
        "#                 Y = Y.cuda()  \n",
        "            yield Variable(X), Variable(Y)\n",
        "            start_idx += batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rk6ykajFYDRe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(data, X, Y, model, evaluateL2, evaluateL1, batch_size):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_loss_l1 = 0\n",
        "    n_samples = 0\n",
        "    predict = None\n",
        "    test = None\n",
        "    \n",
        "    for X, Y in data.get_batches(X, Y, batch_size, False):\n",
        "        output = model(X)\n",
        "        if predict is None:\n",
        "            predict = output\n",
        "            test = Y\n",
        "        else:\n",
        "            predict = torch.cat((predict,output))\n",
        "            test = torch.cat((test, Y))\n",
        "        \n",
        "        scale = data.scale.expand(output.size(0), data.m)\n",
        "        total_loss += evaluateL2(output * scale, Y * scale).data\n",
        "        total_loss_l1 += evaluateL1(output * scale, Y * scale).data\n",
        "        n_samples += (output.size(0) * data.m)\n",
        "    rse = math.sqrt(total_loss / n_samples)/data.rse\n",
        "    rae = (total_loss_l1/n_samples)/data.rae\n",
        "    \n",
        "    predict = predict.data.cpu().numpy()\n",
        "    Ytest = test.data.cpu().numpy()\n",
        "    sigma_p = (predict).std(axis = 0)\n",
        "    sigma_g = (Ytest).std(axis = 0)\n",
        "    mean_p = predict.mean(axis = 0)\n",
        "    mean_g = Ytest.mean(axis = 0)\n",
        "    index = (sigma_g!=0)\n",
        "    correlation = ((predict - mean_p) * (Ytest - mean_g)).mean(axis = 0)/(sigma_p * sigma_g)\n",
        "    correlation = (correlation[index]).mean()\n",
        "    return rse, rae, correlation\n",
        "\n",
        "def train(data, X, Y, model, criterion, batch_size):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    n_samples = 0\n",
        "    for X, Y in data.get_batches(X, Y, batch_size, True):\n",
        "        model.zero_grad()\n",
        "        output = model(X)\n",
        "        scale = data.scale.expand(output.size(0), data.m)\n",
        "        loss = criterion(output * scale, Y * scale)\n",
        "        loss.backward()\n",
        "        grad_norm = optim.step()\n",
        "        total_loss += loss.data\n",
        "        n_samples += (output.size(0) * data.m);\n",
        "    return total_loss / n_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KLfPja3974O",
        "colab_type": "code",
        "outputId": "3af62b7e-ab44-403e-b199-8333b98b2d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/My Drive/LSTNet_data\")\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "electricity.txt  exchange_rate.txt  save  solar_AL.txt\ttraffic.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0UZ9fZi8YOQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Arguments():\n",
        "    def __init__(self,data,hidCNN=100,hidRNN=100,window=35,CNN_kernel=6,highway_window=24,clip=10,epochs=100,batch_size=128,dropout=0.2,save=\"save.pt\",optim=\"adam\",lr=0.001,horizon=12,skip=24,hidSkip=5,L1loss=True,normalize=2,output_fun=\"sigmoid\"):\n",
        "        self.data=data\n",
        "        self.hidCNN=hidCNN\n",
        "        self.hidRNN=hidRNN\n",
        "        self.window=window\n",
        "        self.CNN_kernel=CNN_kernel\n",
        "        self.highway_window=highway_window\n",
        "        self.clip=clip\n",
        "        self.epochs=epochs\n",
        "        self.batch_size=batch_size\n",
        "        self.dropout=dropout\n",
        "        self.optim=optim\n",
        "        self.lr=lr\n",
        "        self.skip=skip\n",
        "        self.normalize=normalize\n",
        "        self.horizon=horizon\n",
        "        self.save=save\n",
        "        self.output_fun=output_fun\n",
        "        self.hidSkip=hidSkip\n",
        "        self.L1Loss=L1loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MxPGjHUr7L1h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Execute for exchange rate\n",
        "args=Arguments(horizon=24,hidCNN=50, hidRNN=50,L1loss=False,data=\"exchange_rate.txt\",save=\"save/exchange_rate.pt\",output_fun=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jRtFo05YYWVy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Execute for electricity rate\n",
        "args=Arguments(horizon=24, data=\"electricity.txt\",save=\"save/electricity.pt\",output_fun=\"Linear\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "acSYHqN9Ywg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Execute for solar rate\n",
        "args=Arguments(hidSkip=10, data=\"solar_AL.txt\",save=\"save/solar_AL.pt\",output_fun=\"Linear\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xhoHop94ZCdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Execute for traffic rate\n",
        "args=Arguments(hidSkip=10, data=\"traffic.txt\",save=\"save/traffic.pt\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tja2bn-vU9iA",
        "colab_type": "code",
        "outputId": "a2c9501b-c0f9-487e-8d42-8f62bf64afec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "Data = Data_utility(args.data, 0.6, 0.2, args.horizon, args.window, args.normalize);\n",
        "print(Data.rse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0571)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WcT-q95CVPTx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class Optim(object):\n",
        "\n",
        "    def _makeOptimizer(self):\n",
        "        if self.method == 'sgd':\n",
        "            self.optimizer = optim.SGD(self.params, lr=self.lr)\n",
        "        elif self.method == 'adagrad':\n",
        "            self.optimizer = optim.Adagrad(self.params, lr=self.lr)\n",
        "        elif self.method == 'adadelta':\n",
        "            self.optimizer = optim.Adadelta(self.params, lr=self.lr)\n",
        "        elif self.method == 'adam':\n",
        "            self.optimizer = optim.Adam(self.params, lr=self.lr)\n",
        "        else:\n",
        "            raise RuntimeError(\"Invalid optim method: \" + self.method)\n",
        "\n",
        "    def __init__(self, params, method, lr, max_grad_norm, lr_decay=1, start_decay_at=None):\n",
        "        self.params = list(params)  # careful: params may be a generator\n",
        "        self.last_ppl = None\n",
        "        self.lr = lr\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.method = method\n",
        "        self.lr_decay = lr_decay\n",
        "        self.start_decay_at = start_decay_at\n",
        "        self.start_decay = False\n",
        "\n",
        "        self._makeOptimizer()\n",
        "\n",
        "    def step(self):\n",
        "        # Compute gradients norm.\n",
        "        # Objective Function\n",
        "        grad_norm = 0\n",
        "        for param in self.params:\n",
        "            grad_norm += math.pow(param.grad.data.norm(), 2)\n",
        "\n",
        "        grad_norm = math.sqrt(grad_norm)\n",
        "        if grad_norm > 0:\n",
        "            shrinkage = self.max_grad_norm / grad_norm\n",
        "        else:\n",
        "            shrinkage = 1.\n",
        "\n",
        "        for param in self.params:\n",
        "            if shrinkage < 1:\n",
        "                param.grad.data.mul_(shrinkage)\n",
        "\n",
        "        self.optimizer.step()\n",
        "        return grad_norm\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YJdtWndU_aS",
        "colab_type": "code",
        "outputId": "0d3ef14a-4344-4a6d-833e-2d3b82fa93d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "model = LSTNet(args, Data)\n",
        "nParams = sum([p.nelement() for p in model.parameters()])\n",
        "print('* number of parameters: %d' % nParams)\n",
        "\n",
        "if args.L1Loss:\n",
        "    criterion = nn.L1Loss(size_average=False);\n",
        "else:\n",
        "    criterion = nn.MSELoss(size_average=False);\n",
        "evaluateL2 = nn.MSELoss(size_average=False);\n",
        "evaluateL1 = nn.L1Loss(size_average=False)\n",
        "\n",
        "best_val = 1000000;\n",
        "\n",
        "optim = Optim(\n",
        "    model.parameters(), args.optim, args.lr, args.clip,\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* number of parameters: 875227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lqYEimPZVKO7",
        "colab_type": "code",
        "outputId": "b93af93c-b80a-42c6-e830-f0bca40f6e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2337
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    print('begin training');\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train_loss = train(Data, Data.train[0], Data.train[1], model, criterion, args.batch_size)\n",
        "        val_loss, val_rae, val_corr = evaluate(Data, Data.valid[0], Data.valid[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | train_loss {:5.4f} | valid rse {:5.4f} | valid rae {:5.4f} | valid corr  {:5.4f}'.format(epoch, (time.time() - epoch_start_time), train_loss, val_loss, val_rae, val_corr))\n",
        "        # Save the model if the validation loss is the best we've seen so far.\n",
        "\n",
        "        if val_loss < best_val:\n",
        "            with open(args.save, 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val = val_loss\n",
        "        if epoch % 5 == 0:\n",
        "            test_acc, test_rae, test_corr  = evaluate(Data, Data.test[0], Data.test[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "            print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_acc, test_rae, test_corr))\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "test_rse, test_rae, test_corr  = evaluate(Data, Data.test[0], Data.test[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "\n",
        "print(\"\\n\\n\\n After end of training.\")\n",
        "print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_rse, test_rae, test_corr))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| end of epoch   1 | time: 48.68s | train_loss 0.0329 | valid rse 0.6515 | valid rae 0.5002 | valid corr  0.7765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type LSTNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| end of epoch   2 | time: 48.38s | train_loss 0.0165 | valid rse 0.6038 | valid rae 0.4478 | valid corr  0.8119\n",
            "| end of epoch   3 | time: 47.52s | train_loss 0.0150 | valid rse 0.5568 | valid rae 0.3965 | valid corr  0.8309\n",
            "| end of epoch   4 | time: 47.42s | train_loss 0.0137 | valid rse 0.5611 | valid rae 0.4074 | valid corr  0.8396\n",
            "| end of epoch   5 | time: 47.85s | train_loss 0.0129 | valid rse 0.5571 | valid rae 0.3967 | valid corr  0.8385\n",
            "test rse 0.5799 | test rae 0.4103 | test corr 0.8312\n",
            "| end of epoch   6 | time: 48.40s | train_loss 0.0124 | valid rse 0.5172 | valid rae 0.3574 | valid corr  0.8548\n",
            "| end of epoch   7 | time: 47.62s | train_loss 0.0120 | valid rse 0.5095 | valid rae 0.3477 | valid corr  0.8548\n",
            "| end of epoch   8 | time: 48.19s | train_loss 0.0117 | valid rse 0.4929 | valid rae 0.3333 | valid corr  0.8619\n",
            "| end of epoch   9 | time: 50.21s | train_loss 0.0113 | valid rse 0.4910 | valid rae 0.3386 | valid corr  0.8615\n",
            "| end of epoch  10 | time: 51.68s | train_loss 0.0112 | valid rse 0.5312 | valid rae 0.3764 | valid corr  0.8549\n",
            "test rse 0.5488 | test rae 0.3851 | test corr 0.8501\n",
            "| end of epoch  11 | time: 50.85s | train_loss 0.0111 | valid rse 0.4866 | valid rae 0.3325 | valid corr  0.8668\n",
            "| end of epoch  12 | time: 50.23s | train_loss 0.0109 | valid rse 0.4809 | valid rae 0.3246 | valid corr  0.8684\n",
            "| end of epoch  13 | time: 49.34s | train_loss 0.0107 | valid rse 0.4916 | valid rae 0.3388 | valid corr  0.8691\n",
            "| end of epoch  14 | time: 48.56s | train_loss 0.0106 | valid rse 0.4766 | valid rae 0.3153 | valid corr  0.8696\n",
            "| end of epoch  15 | time: 49.26s | train_loss 0.0105 | valid rse 0.4845 | valid rae 0.3246 | valid corr  0.8680\n",
            "test rse 0.5201 | test rae 0.3573 | test corr 0.8580\n",
            "| end of epoch  16 | time: 50.12s | train_loss 0.0105 | valid rse 0.4732 | valid rae 0.3091 | valid corr  0.8711\n",
            "| end of epoch  17 | time: 49.16s | train_loss 0.0104 | valid rse 0.4741 | valid rae 0.3136 | valid corr  0.8712\n",
            "| end of epoch  18 | time: 49.47s | train_loss 0.0103 | valid rse 0.4854 | valid rae 0.3325 | valid corr  0.8683\n",
            "| end of epoch  19 | time: 49.64s | train_loss 0.0102 | valid rse 0.4758 | valid rae 0.3107 | valid corr  0.8714\n",
            "| end of epoch  20 | time: 49.50s | train_loss 0.0101 | valid rse 0.4700 | valid rae 0.3116 | valid corr  0.8723\n",
            "test rse 0.5178 | test rae 0.3605 | test corr 0.8563\n",
            "| end of epoch  21 | time: 49.38s | train_loss 0.0101 | valid rse 0.4753 | valid rae 0.3252 | valid corr  0.8720\n",
            "| end of epoch  22 | time: 49.78s | train_loss 0.0100 | valid rse 0.4722 | valid rae 0.3110 | valid corr  0.8718\n",
            "| end of epoch  23 | time: 49.29s | train_loss 0.0100 | valid rse 0.4647 | valid rae 0.3033 | valid corr  0.8730\n",
            "| end of epoch  24 | time: 48.93s | train_loss 0.0099 | valid rse 0.4968 | valid rae 0.3510 | valid corr  0.8687\n",
            "| end of epoch  25 | time: 48.63s | train_loss 0.0099 | valid rse 0.4677 | valid rae 0.3004 | valid corr  0.8734\n",
            "test rse 0.5170 | test rae 0.3526 | test corr 0.8563\n",
            "| end of epoch  26 | time: 49.33s | train_loss 0.0099 | valid rse 0.4696 | valid rae 0.3095 | valid corr  0.8723\n",
            "| end of epoch  27 | time: 50.09s | train_loss 0.0098 | valid rse 0.4674 | valid rae 0.3115 | valid corr  0.8751\n",
            "| end of epoch  28 | time: 50.06s | train_loss 0.0098 | valid rse 0.4681 | valid rae 0.3101 | valid corr  0.8732\n",
            "| end of epoch  29 | time: 49.94s | train_loss 0.0097 | valid rse 0.4638 | valid rae 0.3025 | valid corr  0.8736\n",
            "| end of epoch  30 | time: 49.71s | train_loss 0.0097 | valid rse 0.4687 | valid rae 0.3137 | valid corr  0.8740\n",
            "test rse 0.5110 | test rae 0.3539 | test corr 0.8626\n",
            "| end of epoch  31 | time: 48.43s | train_loss 0.0097 | valid rse 0.4754 | valid rae 0.3189 | valid corr  0.8718\n",
            "| end of epoch  32 | time: 48.57s | train_loss 0.0097 | valid rse 0.4824 | valid rae 0.3248 | valid corr  0.8690\n",
            "| end of epoch  33 | time: 48.44s | train_loss 0.0096 | valid rse 0.4681 | valid rae 0.3107 | valid corr  0.8736\n",
            "| end of epoch  34 | time: 48.39s | train_loss 0.0096 | valid rse 0.4652 | valid rae 0.3019 | valid corr  0.8741\n",
            "| end of epoch  35 | time: 48.94s | train_loss 0.0096 | valid rse 0.4649 | valid rae 0.3048 | valid corr  0.8747\n",
            "test rse 0.5184 | test rae 0.3611 | test corr 0.8557\n",
            "| end of epoch  36 | time: 49.87s | train_loss 0.0095 | valid rse 0.4750 | valid rae 0.3167 | valid corr  0.8733\n",
            "| end of epoch  37 | time: 49.25s | train_loss 0.0095 | valid rse 0.4610 | valid rae 0.2970 | valid corr  0.8758\n",
            "| end of epoch  38 | time: 50.23s | train_loss 0.0095 | valid rse 0.4807 | valid rae 0.3182 | valid corr  0.8707\n",
            "| end of epoch  39 | time: 49.42s | train_loss 0.0094 | valid rse 0.4653 | valid rae 0.3094 | valid corr  0.8743\n",
            "| end of epoch  40 | time: 49.20s | train_loss 0.0094 | valid rse 0.4628 | valid rae 0.3011 | valid corr  0.8753\n",
            "test rse 0.5047 | test rae 0.3412 | test corr 0.8644\n",
            "| end of epoch  41 | time: 48.91s | train_loss 0.0093 | valid rse 0.4712 | valid rae 0.3049 | valid corr  0.8728\n",
            "| end of epoch  42 | time: 49.50s | train_loss 0.0093 | valid rse 0.4779 | valid rae 0.3267 | valid corr  0.8719\n",
            "| end of epoch  43 | time: 49.57s | train_loss 0.0093 | valid rse 0.4631 | valid rae 0.3034 | valid corr  0.8745\n",
            "| end of epoch  44 | time: 49.11s | train_loss 0.0093 | valid rse 0.4642 | valid rae 0.3054 | valid corr  0.8742\n",
            "| end of epoch  45 | time: 49.74s | train_loss 0.0093 | valid rse 0.4563 | valid rae 0.2964 | valid corr  0.8762\n",
            "test rse 0.5121 | test rae 0.3535 | test corr 0.8577\n",
            "| end of epoch  46 | time: 48.58s | train_loss 0.0093 | valid rse 0.4655 | valid rae 0.3030 | valid corr  0.8727\n",
            "| end of epoch  47 | time: 48.95s | train_loss 0.0092 | valid rse 0.4649 | valid rae 0.3090 | valid corr  0.8755\n",
            "| end of epoch  48 | time: 49.19s | train_loss 0.0092 | valid rse 0.4599 | valid rae 0.2953 | valid corr  0.8755\n",
            "| end of epoch  49 | time: 50.35s | train_loss 0.0091 | valid rse 0.4682 | valid rae 0.3029 | valid corr  0.8739\n",
            "| end of epoch  50 | time: 50.34s | train_loss 0.0091 | valid rse 0.4702 | valid rae 0.3112 | valid corr  0.8745\n",
            "test rse 0.5058 | test rae 0.3455 | test corr 0.8655\n",
            "| end of epoch  51 | time: 50.55s | train_loss 0.0091 | valid rse 0.4773 | valid rae 0.3153 | valid corr  0.8704\n",
            "| end of epoch  52 | time: 49.68s | train_loss 0.0091 | valid rse 0.4629 | valid rae 0.3028 | valid corr  0.8754\n",
            "| end of epoch  53 | time: 49.18s | train_loss 0.0091 | valid rse 0.4622 | valid rae 0.3000 | valid corr  0.8749\n",
            "| end of epoch  54 | time: 48.57s | train_loss 0.0090 | valid rse 0.4651 | valid rae 0.3020 | valid corr  0.8754\n",
            "| end of epoch  55 | time: 48.56s | train_loss 0.0090 | valid rse 0.4621 | valid rae 0.2983 | valid corr  0.8751\n",
            "test rse 0.5133 | test rae 0.3514 | test corr 0.8579\n",
            "| end of epoch  56 | time: 48.40s | train_loss 0.0090 | valid rse 0.4630 | valid rae 0.2994 | valid corr  0.8751\n",
            "| end of epoch  57 | time: 48.01s | train_loss 0.0090 | valid rse 0.4721 | valid rae 0.3113 | valid corr  0.8734\n",
            "| end of epoch  58 | time: 49.80s | train_loss 0.0089 | valid rse 0.4539 | valid rae 0.2910 | valid corr  0.8777\n",
            "| end of epoch  59 | time: 50.10s | train_loss 0.0090 | valid rse 0.4669 | valid rae 0.3076 | valid corr  0.8753\n",
            "| end of epoch  60 | time: 49.92s | train_loss 0.0090 | valid rse 0.4622 | valid rae 0.2981 | valid corr  0.8767\n",
            "test rse 0.5090 | test rae 0.3455 | test corr 0.8618\n",
            "| end of epoch  61 | time: 50.43s | train_loss 0.0089 | valid rse 0.4603 | valid rae 0.2954 | valid corr  0.8758\n",
            "| end of epoch  62 | time: 49.42s | train_loss 0.0089 | valid rse 0.4622 | valid rae 0.3048 | valid corr  0.8759\n",
            "| end of epoch  63 | time: 49.31s | train_loss 0.0089 | valid rse 0.4608 | valid rae 0.3024 | valid corr  0.8765\n",
            "| end of epoch  64 | time: 48.82s | train_loss 0.0089 | valid rse 0.4649 | valid rae 0.3040 | valid corr  0.8750\n",
            "| end of epoch  65 | time: 50.19s | train_loss 0.0088 | valid rse 0.4620 | valid rae 0.2956 | valid corr  0.8750\n",
            "test rse 0.5056 | test rae 0.3423 | test corr 0.8630\n",
            "| end of epoch  66 | time: 49.22s | train_loss 0.0088 | valid rse 0.4569 | valid rae 0.2914 | valid corr  0.8761\n",
            "| end of epoch  67 | time: 48.99s | train_loss 0.0088 | valid rse 0.4694 | valid rae 0.3078 | valid corr  0.8740\n",
            "| end of epoch  68 | time: 48.76s | train_loss 0.0088 | valid rse 0.4560 | valid rae 0.2963 | valid corr  0.8762\n",
            "| end of epoch  69 | time: 48.31s | train_loss 0.0088 | valid rse 0.4554 | valid rae 0.2892 | valid corr  0.8783\n",
            "| end of epoch  70 | time: 49.35s | train_loss 0.0088 | valid rse 0.4709 | valid rae 0.3077 | valid corr  0.8712\n",
            "test rse 0.5015 | test rae 0.3377 | test corr 0.8666\n",
            "| end of epoch  71 | time: 49.98s | train_loss 0.0088 | valid rse 0.4565 | valid rae 0.2902 | valid corr  0.8755\n",
            "| end of epoch  72 | time: 49.79s | train_loss 0.0087 | valid rse 0.4544 | valid rae 0.2886 | valid corr  0.8767\n",
            "| end of epoch  73 | time: 49.36s | train_loss 0.0087 | valid rse 0.4608 | valid rae 0.2939 | valid corr  0.8750\n",
            "| end of epoch  74 | time: 47.97s | train_loss 0.0087 | valid rse 0.4596 | valid rae 0.3000 | valid corr  0.8752\n",
            "| end of epoch  75 | time: 50.19s | train_loss 0.0087 | valid rse 0.4533 | valid rae 0.2883 | valid corr  0.8780\n",
            "test rse 0.4999 | test rae 0.3354 | test corr 0.8653\n",
            "| end of epoch  76 | time: 49.06s | train_loss 0.0087 | valid rse 0.4582 | valid rae 0.2921 | valid corr  0.8763\n",
            "| end of epoch  77 | time: 48.18s | train_loss 0.0087 | valid rse 0.4652 | valid rae 0.3001 | valid corr  0.8736\n",
            "| end of epoch  78 | time: 48.50s | train_loss 0.0086 | valid rse 0.4580 | valid rae 0.2939 | valid corr  0.8758\n",
            "| end of epoch  79 | time: 47.66s | train_loss 0.0086 | valid rse 0.4597 | valid rae 0.2924 | valid corr  0.8751\n",
            "| end of epoch  80 | time: 47.88s | train_loss 0.0086 | valid rse 0.4571 | valid rae 0.2916 | valid corr  0.8767\n",
            "test rse 0.5046 | test rae 0.3402 | test corr 0.8627\n",
            "| end of epoch  81 | time: 48.27s | train_loss 0.0086 | valid rse 0.4599 | valid rae 0.2950 | valid corr  0.8748\n",
            "| end of epoch  82 | time: 49.16s | train_loss 0.0086 | valid rse 0.4553 | valid rae 0.2898 | valid corr  0.8763\n",
            "| end of epoch  83 | time: 49.20s | train_loss 0.0086 | valid rse 0.4653 | valid rae 0.3008 | valid corr  0.8738\n",
            "| end of epoch  84 | time: 49.88s | train_loss 0.0086 | valid rse 0.4570 | valid rae 0.2939 | valid corr  0.8754\n",
            "| end of epoch  85 | time: 49.11s | train_loss 0.0086 | valid rse 0.4628 | valid rae 0.2986 | valid corr  0.8749\n",
            "test rse 0.5049 | test rae 0.3393 | test corr 0.8642\n",
            "| end of epoch  86 | time: 50.16s | train_loss 0.0086 | valid rse 0.4615 | valid rae 0.2967 | valid corr  0.8747\n",
            "| end of epoch  87 | time: 49.44s | train_loss 0.0085 | valid rse 0.4606 | valid rae 0.2945 | valid corr  0.8743\n",
            "| end of epoch  88 | time: 48.37s | train_loss 0.0085 | valid rse 0.4588 | valid rae 0.2912 | valid corr  0.8750\n",
            "| end of epoch  89 | time: 49.22s | train_loss 0.0085 | valid rse 0.4631 | valid rae 0.2961 | valid corr  0.8750\n",
            "| end of epoch  90 | time: 50.04s | train_loss 0.0085 | valid rse 0.4583 | valid rae 0.2909 | valid corr  0.8746\n",
            "test rse 0.5121 | test rae 0.3456 | test corr 0.8567\n",
            "| end of epoch  91 | time: 49.53s | train_loss 0.0085 | valid rse 0.4583 | valid rae 0.2924 | valid corr  0.8755\n",
            "| end of epoch  92 | time: 50.24s | train_loss 0.0085 | valid rse 0.4571 | valid rae 0.2921 | valid corr  0.8759\n",
            "| end of epoch  93 | time: 49.77s | train_loss 0.0085 | valid rse 0.4629 | valid rae 0.2958 | valid corr  0.8729\n",
            "| end of epoch  94 | time: 49.11s | train_loss 0.0085 | valid rse 0.4521 | valid rae 0.2858 | valid corr  0.8782\n",
            "| end of epoch  95 | time: 48.63s | train_loss 0.0085 | valid rse 0.4561 | valid rae 0.2901 | valid corr  0.8761\n",
            "test rse 0.5026 | test rae 0.3353 | test corr 0.8633\n",
            "| end of epoch  96 | time: 48.18s | train_loss 0.0085 | valid rse 0.4551 | valid rae 0.2890 | valid corr  0.8768\n",
            "| end of epoch  97 | time: 49.10s | train_loss 0.0085 | valid rse 0.4607 | valid rae 0.2967 | valid corr  0.8752\n",
            "| end of epoch  98 | time: 48.95s | train_loss 0.0084 | valid rse 0.4602 | valid rae 0.2931 | valid corr  0.8755\n",
            "| end of epoch  99 | time: 48.79s | train_loss 0.0084 | valid rse 0.4642 | valid rae 0.2975 | valid corr  0.8740\n",
            "| end of epoch 100 | time: 49.30s | train_loss 0.0084 | valid rse 0.4618 | valid rae 0.2969 | valid corr  0.8730\n",
            "test rse 0.4980 | test rae 0.3322 | test corr 0.8652\n",
            "\n",
            "\n",
            "\n",
            " After end of training.\n",
            "test rse 0.4969 | test rae 0.3311 | test corr 0.8659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XNA5wXoIVcJ9",
        "colab_type": "code",
        "outputId": "a9510661-4c5a-499e-a3b4-9f796517727f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Results of exchange rate\n",
        "args=Arguments(horizon=24,hidCNN=50, hidRNN=50,L1loss=False,data=\"exchange_rate.txt\",save=\"save/exchange_rate.pt\",output_fun=None)\n",
        "Data = Data_utility(args.data, 0.6, 0.2, args.horizon, args.window, args.normalize);\n",
        "\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "test_acc, test_rae, test_corr  = evaluate(Data, Data.test[0], Data.test[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "\n",
        "print(\"Results of exchange rate.\")\n",
        "print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_acc, test_rae, test_corr))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of exchange rate.\n",
            "test rse 0.0531 | test rae 0.0469 | test corr 0.9362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jNtVt6NJapVF",
        "colab_type": "code",
        "outputId": "8217e39e-e097-4767-8bb9-3d7f1d9e48b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "#Results of electricity rate\n",
        "args=Arguments(horizon=24, data=\"electricity.txt\",save=\"save/electricity.pt\",output_fun=\"Linear\")\n",
        "Data = Data_utility(args.data, 0.6, 0.2, args.horizon, args.window, args.normalize);\n",
        "\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "test_acc, test_rae, test_corr  = evaluate(Data, Data.test[0], Data.test[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "\n",
        "print(\"Results of electricity rate.\")\n",
        "print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_acc, test_rae, test_corr))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of electricity rate.\n",
            "test rse 0.1000 | test rae 0.0544 | test corr 0.8983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yjEMbhYNpnKD",
        "colab_type": "code",
        "outputId": "dd23553f-6645-4530-c506-d790d0690d41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Results of solar rate\n",
        "args=Arguments(hidSkip=10, data=\"solar_AL.txt\",save=\"save/solar_AL.pt\",output_fun=\"Linear\")\n",
        "Data = Data_utility(args.data, 0.6, 0.2, args.horizon, args.window, args.normalize);\n",
        "\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "test_acc, test_rae, test_corr  = evaluate(Data, Data.test[0], Data.test[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "\n",
        "print(\"Results of solar rate.\")\n",
        "print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_acc, test_rae, test_corr))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of solar rate.\n",
            "test rse 0.4282 | test rae 0.2372 | test corr 0.9087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ld_ShR3Lq2W0",
        "colab_type": "code",
        "outputId": "95953df6-0cf7-455f-bbe2-b83e4d69ccb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "#Results of traffic rate\n",
        "args=Arguments(hidSkip=10, data=\"traffic.txt\",save=\"save/traffic.pt\")\n",
        "Data = Data_utility(args.data, 0.6, 0.2, args.horizon, args.window, args.normalize);\n",
        "\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "test_acc, test_rae, test_corr  = evaluate(Data, Data.test[0], Data.test[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "\n",
        "print(\"Results of traffic rate.\")\n",
        "print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_acc, test_rae, test_corr))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results of traffic rate.\n",
            "test rse 0.4969 | test rae 0.3311 | test corr 0.8659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R_BEyb5340sC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}